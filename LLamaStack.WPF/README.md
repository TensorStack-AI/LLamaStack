## LLamaStack.WPF - Basic WPF UI example
LLamaStack.WPF is a lightweight barebones UI example to run LLM on your local machine, a perfect scaffold to clone and build your own feature rich WPF application


## Setup
You can setup Models, Prompts and Inference parameters in the appsettings.json

**Models**
You can add multiple models to the options for quick selection in the UI, options are based on LLamaSharp ModelParams so its fully configurable


## Interactive UI
Manage and interact with all your models in one sime UI interface
![demo-wpf1](https://i.imgur.com/bGY70wH.png)

## Live Parameters
Update inference parameters between each question/instruction
![demo-wpf2](https://i.imgur.com/uR7KAeY.png)

## Output Log
Output of llama.cpp output into the UI for easy debugging
![demo-wpf3](https://i.imgur.com/Witubi5.png)
